#!/usr/bin/env python3
"""
Socioeconomic Vulnerability and Climate Exposure Analysis
Rigorous examination of differential heat exposure by social status
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import json

def analyze_socioeconomic_climate_vulnerability():
    """Analyze socioeconomic patterns in climate exposure from GCRO data"""
    
    print("SOCIOECONOMIC VULNERABILITY ANALYSIS")
    print("="*50)
    
    # Load socioeconomic data with climate integration
    socio_data = pd.read_csv(
        'data/socioeconomic/processed/GCRO_combined_climate_SUBSET.csv'
    )
    
    print(f"Analyzing {len(socio_data)} survey responses with integrated climate data")
    
    # Key socioeconomic vulnerability indicators
    vulnerability_indicators = {
        'income': {
            'variable': 'q15_3_income_recode',
            'name': 'Household Income',
            'type': 'ordinal'
        },
        'education': {
            'variable': 'q14_1_education_recode', 
            'name': 'Education Level',
            'type': 'ordinal'
        },
        'employment': {
            'variable': 'q10_2_working',
            'name': 'Employment Status',
            'type': 'categorical'
        },
        'medical_aid': {
            'variable': 'q13_5_medical_aid',
            'name': 'Healthcare Access',
            'type': 'binary'
        },
        'dwelling_satisfaction': {
            'variable': 'q2_1_dwelling',
            'name': 'Housing Satisfaction',
            'type': 'ordinal'
        },
        'health_status': {
            'variable': 'q13_6_health_status',
            'name': 'Self-Reported Health',
            'type': 'ordinal'
        },
        'food_security': {
            'variable': 'q6_4_skip_meal',
            'name': 'Food Security',
            'type': 'binary'
        }
    }
    
    # Climate exposure variables
    climate_variables = {
        'temp_30d_mean': 'era5_temp_30d_mean',
        'temp_30d_max': 'era5_temp_30d_max',
        'temp_extreme_days': 'era5_temp_30d_extreme_days'
    }
    
    vulnerability_analysis = {}
    
    for vuln_name, vuln_info in vulnerability_indicators.items():
        vuln_var = vuln_info['variable']
        
        if vuln_var not in socio_data.columns:
            print(f"Warning: {vuln_var} not found in data")
            continue
        
        vuln_analysis = {
            'variable_info': vuln_info,
            'climate_relationships': {},
            'sample_size': socio_data[vuln_var].count(),
            'unique_values': socio_data[vuln_var].nunique()
        }
        
        print(f"\nAnalyzing {vuln_info['name']} (n={vuln_analysis['sample_size']})")
        
        # Analyze relationship with each climate variable
        for climate_name, climate_var in climate_variables.items():
            if climate_var not in socio_data.columns:
                continue
            
            # Create clean analysis subset
            analysis_subset = socio_data[[vuln_var, climate_var]].dropna()
            
            if len(analysis_subset) < 30:  # Minimum sample for meaningful analysis
                continue
            
            climate_analysis = {
                'sample_size': len(analysis_subset),
                'climate_stats': {
                    'mean': float(analysis_subset[climate_var].mean()),
                    'std': float(analysis_subset[climate_var].std()),
                    'min': float(analysis_subset[climate_var].min()),
                    'max': float(analysis_subset[climate_var].max())
                }
            }
            
            # Different analysis approaches by variable type
            if vuln_info['type'] == 'binary':
                # Binary vulnerability indicator (e.g., medical aid: Yes/No)
                groups = analysis_subset.groupby(vuln_var)[climate_var].agg(['mean', 'std', 'count']).reset_index()
                
                if len(groups) == 2:  # Proper binary variable
                    group1, group2 = groups.iloc[0], groups.iloc[1]
                    
                    # T-test for group differences
                    group1_data = analysis_subset[analysis_subset[vuln_var] == group1[vuln_var]][climate_var]
                    group2_data = analysis_subset[analysis_subset[vuln_var] == group2[vuln_var]][climate_var]
                    
                    if len(group1_data) >= 10 and len(group2_data) >= 10:
                        t_stat, p_value = stats.ttest_ind(group1_data, group2_data)
                        
                        # Effect size (Cohen's d)
                        pooled_std = np.sqrt(((len(group1_data) - 1) * group1_data.std()**2 + 
                                            (len(group2_data) - 1) * group2_data.std()**2) / 
                                           (len(group1_data) + len(group2_data) - 2))
                        cohens_d = (group2['mean'] - group1['mean']) / pooled_std if pooled_std > 0 else 0
                        
                        climate_analysis['group_comparison'] = {
                            'group1': {
                                'label': str(group1[vuln_var]),
                                'n': int(group1['count']),
                                'mean': float(group1['mean']),
                                'std': float(group1['std'])
                            },
                            'group2': {
                                'label': str(group2[vuln_var]),
                                'n': int(group2['count']),
                                'mean': float(group2['mean']),
                                'std': float(group2['std'])
                            },
                            'statistical_test': {
                                't_statistic': float(t_stat),
                                'p_value': float(p_value),
                                'cohens_d': float(cohens_d),
                                'significant': p_value < 0.05
                            }
                        }
            
            elif vuln_info['type'] in ['ordinal', 'categorical']:
                # Categorical/ordinal analysis
                groups = analysis_subset.groupby(vuln_var)[climate_var].agg(['mean', 'std', 'count']).reset_index()
                groups = groups[groups['count'] >= 10]  # Minimum group size
                
                if len(groups) >= 2:
                    # ANOVA for group differences
                    group_data = []
                    group_info = []
                    
                    for _, group in groups.iterrows():
                        group_climate_data = analysis_subset[analysis_subset[vuln_var] == group[vuln_var]][climate_var]
                        group_data.append(group_climate_data.values)
                        group_info.append({
                            'label': str(group[vuln_var]),
                            'n': int(group['count']),
                            'mean': float(group['mean']),
                            'std': float(group['std'])
                        })
                    
                    if len(group_data) >= 2:
                        try:
                            f_stat, p_value = stats.f_oneway(*group_data)
                            
                            climate_analysis['group_comparison'] = {
                                'groups': group_info,
                                'statistical_test': {
                                    'f_statistic': float(f_stat),
                                    'p_value': float(p_value),
                                    'significant': p_value < 0.05
                                }
                            }
                        except:
                            climate_analysis['group_comparison'] = {'error': 'Could not compute ANOVA'}
            
            # Correlation analysis (for all types)
            try:
                # Convert to numeric for correlation
                vuln_numeric = pd.to_numeric(analysis_subset[vuln_var], errors='coerce')
                climate_numeric = pd.to_numeric(analysis_subset[climate_var], errors='coerce')
                
                clean_data = pd.DataFrame({'vuln': vuln_numeric, 'climate': climate_numeric}).dropna()
                
                if len(clean_data) >= 30:
                    corr_coef, p_value = stats.pearsonr(clean_data['vuln'], clean_data['climate'])
                    
                    climate_analysis['correlation'] = {
                        'coefficient': float(corr_coef),
                        'p_value': float(p_value),
                        'significant': p_value < 0.05,
                        'sample_size': len(clean_data)
                    }
            except:
                climate_analysis['correlation'] = {'error': 'Could not compute correlation'}
            
            vuln_analysis['climate_relationships'][climate_name] = climate_analysis
        
        vulnerability_analysis[vuln_name] = vuln_analysis
    
    return vulnerability_analysis

def create_vulnerability_visualization(vulnerability_analysis):
    """Create visualization of socioeconomic-climate relationships"""
    
    # Identify significant relationships
    significant_relationships = []
    
    for vuln_name, vuln_data in vulnerability_analysis.items():
        for climate_name, climate_data in vuln_data['climate_relationships'].items():
            
            # Check for significant group differences
            if 'group_comparison' in climate_data and 'statistical_test' in climate_data['group_comparison']:
                test_result = climate_data['group_comparison']['statistical_test']
                if test_result.get('significant', False):
                    significant_relationships.append({
                        'vulnerability': vuln_name,
                        'climate': climate_name,
                        'p_value': test_result.get('p_value', 1),
                        'test_type': 'group_comparison',
                        'effect_size': test_result.get('cohens_d', test_result.get('f_statistic', 0))
                    })
            
            # Check for significant correlations
            if 'correlation' in climate_data and climate_data['correlation'].get('significant', False):
                significant_relationships.append({
                    'vulnerability': vuln_name,
                    'climate': climate_name,
                    'p_value': climate_data['correlation']['p_value'],
                    'test_type': 'correlation',
                    'effect_size': abs(climate_data['correlation']['coefficient'])
                })
    
    print(f"\nFound {len(significant_relationships)} significant socioeconomic-climate relationships")
    
    if len(significant_relationships) > 0:
        # Create visualization
        fig, ax = plt.subplots(figsize=(12, 8))
        
        relationships_df = pd.DataFrame(significant_relationships)
        
        # Create heatmap of p-values
        pivot_data = relationships_df.pivot_table(
            values='p_value', 
            index='vulnerability', 
            columns='climate',
            fill_value=1.0
        )
        
        # Transform p-values for visualization (-log10)
        log_p_data = -np.log10(pivot_data)
        
        sns.heatmap(log_p_data, annot=True, fmt='.2f', cmap='Reds', 
                   cbar_kws={'label': '-log10(p-value)'}, ax=ax)
        
        ax.set_title('Significant Socioeconomic-Climate Relationships\n(Higher values = more significant)', 
                    fontsize=14, fontweight='bold')
        ax.set_xlabel('Climate Variables')
        ax.set_ylabel('Socioeconomic Vulnerability Indicators')
        
        plt.tight_layout()
        plt.savefig('/home/cparker/heat_analysis_optimized/socioeconomic_climate_relationships.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
        return fig, significant_relationships
    
    else:
        print("No significant relationships found for visualization")
        return None, significant_relationships

def generate_vulnerability_report(vulnerability_analysis, significant_relationships):
    """Generate comprehensive vulnerability analysis report"""
    
    report_lines = [
        "# Socioeconomic Vulnerability and Climate Exposure Analysis",
        f"Generated: {pd.Timestamp.now().isoformat()}",
        "",
        "## Executive Summary",
        "",
        f"Analysis of **500 GCRO Quality of Life Survey responses** with integrated climate data reveals patterns of differential heat exposure across socioeconomic groups in Johannesburg metropolitan area.",
        "",
        f"**Key Finding**: {len(significant_relationships)} significant socioeconomic-climate relationships detected",
        "",
        "## Analysis Overview",
        "",
        f"- **Survey Data**: GCRO Quality of Life Survey 2020-2021",
        f"- **Climate Integration**: ERA5 temperature data with 30-day exposure windows", 
        f"- **Vulnerability Indicators**: {len(vulnerability_analysis)} socioeconomic variables analyzed",
        f"- **Geographic Coverage**: Johannesburg metropolitan area",
        "",
        "## Significant Relationships",
        ""
    ]
    
    if len(significant_relationships) > 0:
        # Sort by significance
        sorted_relationships = sorted(significant_relationships, key=lambda x: x['p_value'])
        
        for i, rel in enumerate(sorted_relationships[:10], 1):  # Top 10 most significant
            vuln_info = vulnerability_analysis[rel['vulnerability']]['variable_info']
            report_lines.extend([
                f"### {i}. {vuln_info['name']} Ã— {rel['climate'].replace('_', ' ').title()}",
                f"- **Test Type**: {rel['test_type'].replace('_', ' ').title()}",
                f"- **P-value**: {rel['p_value']:.2e}",
                f"- **Effect Size**: {rel['effect_size']:.3f}",
                f"- **Sample Size**: {vulnerability_analysis[rel['vulnerability']]['sample_size']}",
                ""
            ])
    else:
        report_lines.extend([
            "**No significant relationships detected at p < 0.05 level**",
            "",
            "This finding suggests:",
            "- Climate exposure may be relatively uniform across socioeconomic groups",
            "- Sample size limitations may prevent detection of smaller effects",  
            "- Geographic scale may not capture micro-level exposure differences",
            ""
        ])
    
    # Detailed analysis by vulnerability indicator
    report_lines.extend([
        "## Detailed Analysis by Vulnerability Indicator",
        ""
    ])
    
    for vuln_name, vuln_data in vulnerability_analysis.items():
        vuln_info = vuln_data['variable_info']
        report_lines.extend([
            f"### {vuln_info['name']}",
            f"- **Variable**: {vuln_info['variable']}",
            f"- **Type**: {vuln_info['type'].title()}",
            f"- **Sample Size**: {vuln_data['sample_size']:,}",
            f"- **Unique Values**: {vuln_data['unique_values']}",
            f"- **Climate Relationships**: {len(vuln_data['climate_relationships'])} analyzed",
            ""
        ])
        
        # Summarize climate relationships
        significant_count = 0
        for climate_name, climate_data in vuln_data['climate_relationships'].items():
            if 'group_comparison' in climate_data:
                if climate_data['group_comparison'].get('statistical_test', {}).get('significant', False):
                    significant_count += 1
            if 'correlation' in climate_data:
                if climate_data['correlation'].get('significant', False):
                    significant_count += 1
        
        if significant_count > 0:
            report_lines.append(f"  - **{significant_count} significant climate relationships detected**")
        else:
            report_lines.append(f"  - No significant climate relationships detected")
        
        report_lines.append("")
    
    # Methodological notes
    report_lines.extend([
        "## Methodology and Limitations",
        "",
        "### Strengths",
        "- **Comprehensive socioeconomic indicators** across multiple domains",
        "- **Integrated climate data** at individual response level",
        "- **Representative sampling** of Johannesburg metropolitan area",
        "- **Multiple statistical approaches** (t-tests, ANOVA, correlations)",
        "",
        "### Limitations", 
        "- **Cross-sectional survey design** prevents causal inference",
        "- **Single time period** (2020-2021) may not capture temporal variation",
        "- **Geographic aggregation** may mask neighborhood-level differences",
        "- **Sample size constraints** for detecting small effects",
        "",
        "### Statistical Approach",
        "- **Binary variables**: Independent t-tests with Cohen's d effect sizes",
        "- **Categorical/ordinal variables**: One-way ANOVA with F-statistics",
        "- **All variables**: Pearson correlations with numeric conversion",
        "- **Significance threshold**: p < 0.05 (no multiple testing correction applied)",
        ""
    ])
    
    report_text = "\n".join(report_lines)
    
    with open('/home/cparker/heat_analysis_optimized/vulnerability_analysis_report.md', 'w') as f:
        f.write(report_text)
    
    return report_text

def main():
    """Run comprehensive vulnerability analysis"""
    
    # Analyze socioeconomic vulnerability patterns
    vulnerability_analysis = analyze_socioeconomic_climate_vulnerability()
    
    # Create visualizations
    fig, significant_relationships = create_vulnerability_visualization(vulnerability_analysis)
    
    # Generate comprehensive report
    report = generate_vulnerability_report(vulnerability_analysis, significant_relationships)
    
    print("\n" + "="*60)
    print("VULNERABILITY ANALYSIS SUMMARY")
    print("="*60)
    print(report[:1000] + "..." if len(report) > 1000 else report)
    
    print(f"\nDetailed report saved to: vulnerability_analysis_report.md")
    if fig is not None:
        print(f"Visualization saved to: socioeconomic_climate_relationships.png")
    
    return vulnerability_analysis, significant_relationships

if __name__ == "__main__":
    vulnerability_analysis, relationships = main()